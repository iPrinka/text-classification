{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Topic_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>American Airlines Flyer Charged, Banned For Li...</td>\n",
       "      <td>AIRLINE INCIDENTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
       "      <td>FUNNY TWEETS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Man Sets Himself On Fire In Apparent Protest O...</td>\n",
       "      <td>HOLIDAYS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Russian Cosmonaut Valery Polyakov Who Broke Re...</td>\n",
       "      <td>AIRLINE INCIDENTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4 Russian-Controlled Ukrainian Regions Schedul...</td>\n",
       "      <td>WORLD POLITICS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Document        Topic_Label\n",
       "0  American Airlines Flyer Charged, Banned For Li...  AIRLINE INCIDENTS\n",
       "1  23 Of The Funniest Tweets About Cats And Dogs ...       FUNNY TWEETS\n",
       "2  Man Sets Himself On Fire In Apparent Protest O...           HOLIDAYS\n",
       "3  Russian Cosmonaut Valery Polyakov Who Broke Re...  AIRLINE INCIDENTS\n",
       "4  4 Russian-Controlled Ukrainian Regions Schedul...     WORLD POLITICS"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df = pd.read_csv('supervised_input.csv')\n",
    "input_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = input_df['Document'].to_list()\n",
    "text_labels = input_df['Topic_Label'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Labels - because model understands numbers not text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIRLINE INCIDENTS: 0\n",
      "ANIMALS: 1\n",
      "ART & HOME: 2\n",
      "BUSINESS: 3\n",
      "CLIMATE: 4\n",
      "CRIME: 5\n",
      "DATING & MARRIAGE: 6\n",
      "EDUCATION: 7\n",
      "FASHION: 8\n",
      "FOOD & DRINK: 9\n",
      "FUNNY TWEETS: 10\n",
      "HEALTH: 11\n",
      "HOLIDAYS: 12\n",
      "MENTAL HEALTH: 13\n",
      "MOVIES: 14\n",
      "MUSIC: 15\n",
      "OTHER: 16\n",
      "PARENTING: 17\n",
      "QUEER VOICES: 18\n",
      "ROYAL FAMILY: 19\n",
      "SCIENCE & HISTORY: 20\n",
      "SPORTS: 21\n",
      "STYLE: 22\n",
      "TECHNOLOGY: 23\n",
      "TRAVEL: 24\n",
      "US POLITICS: 25\n",
      "WEATHER NEWS: 26\n",
      "WEIRD NEWS: 27\n",
      "WELLNESS: 28\n",
      "WORLD POLITICS: 29\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoded_labels = encoder.fit_transform(text_labels)\n",
    "\n",
    "for label, number in zip(encoder.classes_, encoder.transform(encoder.classes_)):\n",
    "    print(f'{label}: {number}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_texts = docs\n",
    "data_labels = encoded_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test-Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58596\n",
      "58596\n",
      "592\n",
      "592\n",
      "14797\n",
      "14797\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(data_texts, data_labels, test_size = 0.2, random_state = 42, stratify=data_labels)\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(train_texts, train_labels, test_size = 0.01, random_state = 42, stratify=train_labels)\n",
    "\n",
    "print(len(train_texts))\n",
    "print(len(train_labels))\n",
    "print(len(test_texts))\n",
    "print(len(test_labels))\n",
    "print(len(val_texts))\n",
    "print(len(val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Tokenizer to create encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iprinka/Desktop/Projects/text-classification/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/iprinka/Desktop/Projects/text-classification/venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "train_encodings = tokenizer(train_texts, truncation = True, padding = True  )\n",
    "val_encodings = tokenizer(val_texts, truncation = True, padding = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train_labels\n",
    "))\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(val_encodings),\n",
    "    val_labels\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFDistilBertForSequenceClassification\n",
    "\n",
    "model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=30)\n",
    "\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=5e-5, epsilon=1e-08)\n",
    "model.compile(optimizer=optimizer, loss=model.hf_compute_loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "3663/3663 [==============================] - 10614s 3s/step - loss: 0.7077 - accuracy: 0.8153 - val_loss: 0.4092 - val_accuracy: 0.8839\n",
      "Epoch 2/2\n",
      "3663/3663 [==============================] - 12536s 3s/step - loss: 0.2289 - accuracy: 0.9363 - val_loss: 0.3900 - val_accuracy: 0.8939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x17229ff70>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "model.fit(train_dataset.shuffle(1000).batch(16),\n",
    "        epochs=2,\n",
    "        batch_size=16,\n",
    "        validation_data=val_dataset.shuffle(1000).batch(16),\n",
    "        callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_distil_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " distilbert (TFDistilBertMa  multiple                  66362880  \n",
      " inLayer)                                                        \n",
      "                                                                 \n",
      " pre_classifier (Dense)      multiple                  590592    \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  23070     \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66976542 (255.50 MB)\n",
      "Trainable params: 66976542 (255.50 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Display the model's architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('iprinka_news_classifier/tokenizer_config.json',\n",
       " 'iprinka_news_classifier/special_tokens_map.json',\n",
       " 'iprinka_news_classifier/vocab.txt',\n",
       " 'iprinka_news_classifier/added_tokens.json')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_directory = \"iprinka_news_classifier\"\n",
    "\n",
    "model.save_pretrained(save_directory)\n",
    "tokenizer.save_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at iprinka_news_classifier were not used when initializing TFDistilBertForSequenceClassification: ['dropout_19']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at iprinka_news_classifier and are newly initialized: ['dropout_39']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "loaded_tokenizer = DistilBertTokenizer.from_pretrained(save_directory)\n",
    "loaded_model = TFDistilBertForSequenceClassification.from_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_category(text):\n",
    "\n",
    "    predict_input = loaded_tokenizer.encode(text,\n",
    "                                 truncation=True,\n",
    "                                 padding=True,\n",
    "                                 return_tensors=\"tf\")\n",
    "\n",
    "    output = loaded_model(predict_input)\n",
    "\n",
    "    prediction_value = tf.argmax(output[0], axis=1).numpy()[0]\n",
    "    prediction_probability = tf.reduce_max(tf.nn.softmax(output.logits, axis=1)).numpy()\n",
    "\n",
    "    if prediction_probability < 0.5:\n",
    "        prediction_value = -1\n",
    "\n",
    "    return prediction_value,prediction_probability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reassign textual labels back to the output for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{np.int64(0): np.str_('AIRLINE INCIDENTS'),\n",
       " np.int64(1): np.str_('ANIMALS'),\n",
       " np.int64(2): np.str_('ART & HOME'),\n",
       " np.int64(3): np.str_('BUSINESS'),\n",
       " np.int64(4): np.str_('CLIMATE'),\n",
       " np.int64(5): np.str_('CRIME'),\n",
       " np.int64(6): np.str_('DATING & MARRIAGE'),\n",
       " np.int64(7): np.str_('EDUCATION'),\n",
       " np.int64(8): np.str_('FASHION'),\n",
       " np.int64(9): np.str_('FOOD & DRINK'),\n",
       " np.int64(10): np.str_('FUNNY TWEETS'),\n",
       " np.int64(11): np.str_('HEALTH'),\n",
       " np.int64(12): np.str_('HOLIDAYS'),\n",
       " np.int64(13): np.str_('MENTAL HEALTH'),\n",
       " np.int64(14): np.str_('MOVIES'),\n",
       " np.int64(15): np.str_('MUSIC'),\n",
       " np.int64(16): np.str_('OTHER'),\n",
       " np.int64(17): np.str_('PARENTING'),\n",
       " np.int64(18): np.str_('QUEER VOICES'),\n",
       " np.int64(19): np.str_('ROYAL FAMILY'),\n",
       " np.int64(20): np.str_('SCIENCE & HISTORY'),\n",
       " np.int64(21): np.str_('SPORTS'),\n",
       " np.int64(22): np.str_('STYLE'),\n",
       " np.int64(23): np.str_('TECHNOLOGY'),\n",
       " np.int64(24): np.str_('TRAVEL'),\n",
       " np.int64(25): np.str_('US POLITICS'),\n",
       " np.int64(26): np.str_('WEATHER NEWS'),\n",
       " np.int64(27): np.str_('WEIRD NEWS'),\n",
       " np.int64(28): np.str_('WELLNESS'),\n",
       " np.int64(29): np.str_('WORLD POLITICS')}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map = {}\n",
    "for label, number in zip(encoder.classes_, encoder.transform(encoder.classes_)):\n",
    "    label_map[number] = label\n",
    "\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How Some Evangelicals Rationalize Their Support Of Donald Trump [SEP] \"Full Frontal with Samantha Bee\" asked these conservative Christians why they're supporting Trump.\n",
      "QUEER VOICES 0.99202865\n",
      "Russia Detains Anti-Corruption Protesters In Moscow [SEP] The turnout at the demonstrtion was far smaller than at last week's wave of protests.\n",
      "QUEER VOICES 0.99713624\n",
      "Post-feast Quinoa Salad Makes Thrifty Use of Thanksgiving Leftovers [SEP] It's a delicious way to use a few extra cups of roasted vegetables from your Thanksgiving dinner. My recipe uses three key Cook for Good ideas that can help you sail through the holidays.\n",
      "FOOD & DRINK 0.99853826\n",
      "Valerie Jarrett On Obama's Secret To Finding Fulfillment (VIDEO) [SEP] Watch the video clip above, and head over to our Third Metric page for more inspiration from the conference. In addition\n",
      "UNKNOWN 0.44775578\n",
      "Who Owns Donald Trump? The Fiery Speech Senator Chuck Schumer Must Give To Save Our Country [SEP] Here’s the speech Senate Minority Leader Chuck Schumer must give to rally the country. (Because “Remember The Emoluments\n",
      "US POLITICS 0.9970265\n",
      "Why It's Sometimes OK For Doctors To Google Their Patients [SEP] \n",
      "HEALTH 0.9979482\n",
      "GPS Guide: How Sarah Klein Stays Calm [SEP] The stress and strain of constantly being connected can sometimes take your life -- and your well-being -- off course. GPS\n",
      "WELLNESS 0.9993154\n",
      "How To Clean Soap Scum With Cooking Spray [SEP] Have you tried this trick?\n",
      "ART & HOME 0.9457641\n",
      "Supreme Court Upholds Oklahoma's Use Of Lethal Injection Drug [SEP] \n",
      "HEALTH 0.7724475\n",
      "Behind The Bigotry Of Anti-Transgender Discrimination [SEP] We live in an era of hatred and intolerance directed against those who do not conform to an increasingly archaic set of “norms\n",
      "QUEER VOICES 0.9919892\n"
     ]
    }
   ],
   "source": [
    "test_set = test_texts[0:10]\n",
    "\n",
    "for test_text in test_set:\n",
    "    print(test_text)\n",
    "    val, prob = predict_category(test_text)\n",
    "    label = label_map[val] if val > -1 else \"UNKNOWN\"\n",
    "    print(label, prob)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
